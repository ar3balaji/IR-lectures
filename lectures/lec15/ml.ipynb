{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CS429: Information Retrieval\n",
    "\n",
    "<br>\n",
    "\n",
    "## Lecture 15: Classification and Machine Learning\n",
    "\n",
    "<br>\n",
    "\n",
    "### Dr. Aron Culotta\n",
    "### Illinois Institute of Technology\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is machine learning?\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is machine learning?\n",
    "\n",
    "- [Dietterich: \"Machine Learning\"](http://web.engr.oregonstate.edu/~tgd/publications/nature-ecs-machine-learning.pdf)\n",
    "- [Domingos: \"A few useful things to know about machine learning\"](http://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is machine learning?\n",
    "\n",
    "\"Study of methods for programming computers to learn.\" \n",
    "\n",
    "-- Dietterich\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is machine learning?\n",
    "\n",
    "Study of systems that \"automatically learn programs from data\" \n",
    "\n",
    "-- Domingos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is machine learning?\n",
    "\n",
    "A problem-solving technique that solves future problem instances based on\n",
    "patterns found in past problem instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![spam](images/spam.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='images/search.png' width='50%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='images/netflix.png', width='70%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='images/bw.png' width='50%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='images/chopper.png' width='70%'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='images/car.jpg' width='70%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![money](images/money.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='images/doc.png' width='40%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='images/siri.png' width='40%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='images/watson.png' width='70%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Notation\n",
    "\n",
    "- $\\vec{x} \\in \\mathcal{X}$ &nbsp;&nbsp;&nbsp;&nbsp; *instance*, *example*, *input*\n",
    "  - e.g., an email\n",
    "- $y \\in \\mathcal{Y}$ &nbsp;&nbsp;&nbsp;&nbsp; *target*, *class*, *label*, *output*\n",
    "  - e.g., $y=1$: spam ; $y=0$: not spam\n",
    "- $f: \\mathcal{X} \\mapsto \\mathcal{Y}$ &nbsp;&nbsp;&nbsp;&nbsp; *hypothesis*, *learner*, *model*, *classifier*\n",
    "  - e.g., if $x$ contain the word *free*, $y$ is $1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problem types\n",
    "\n",
    "- **Classification**\n",
    "  - $\\vec{x}$: image of a person ;  $y$: gender\n",
    "- **Regression**\n",
    "  - $\\vec{x}$: image of a person ; $y$: age\n",
    "- **Clustering**\n",
    "  - $\\vec{x}$: images of people ; $y$: cluster id of people that look similar\n",
    "- **Structured classification**\n",
    "  - $\\vec{x}$: image of a person ; $\\vec{y}$: location of their eyes and ears\n",
    "  - $X$: sequence of images of people ; $Y$: subsequences containing people running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Workflow\n",
    "\n",
    "1. **Collect** raw data: emails\n",
    "2. Manually **categorize** them:  spam or not\n",
    "3. **Vectorize**: email -> word counts [**features**]\n",
    "4. **Train** / **Fit**: create $f(x)$\n",
    "5. **Collect** new raw data\n",
    "6. **Predict**: compute $f(x)$ for new $x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Spam Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Steps 1 & 2: Collect and categorize**\n",
    "\n",
    "**Spam:**\n",
    "\n",
    "> Free credit report!\n",
    "\n",
    "\n",
    "> Free money!\n",
    "\n",
    "\n",
    "**Not spam:**\n",
    "\n",
    "> Are you free tonight?\n",
    "\n",
    "> How are you?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Step 3: Vectorize**\n",
    "\n",
    "> 'Free money!'\n",
    "\n",
    "becomes\n",
    "\n",
    "```\n",
    "free: 1\n",
    "money: 1\n",
    "!: 1\n",
    "?: 0\n",
    "credit: 0\n",
    "...\n",
    "```\n",
    "\n",
    "**Representation**: \"Feature engineering is the key\" -- Domingos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Step 4: Train/Fit**\n",
    "\n",
    "Which model to use?\n",
    "\n",
    "- Naive Bayes\n",
    "- Logistic Regression\n",
    "- Decision Tree\n",
    "- K-Nearest Neighbors\n",
    "- Support Vector Machines\n",
    "- ... many many more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Steps 5-6: Predict on new data**\n",
    "\n",
    "> Free vacation!\n",
    "\n",
    "**Spam**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How do you know if it works?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# X: each row is a feature vector for one document.\n",
    "X = [(0, 0),\n",
    "     (1, 0),\n",
    "     (0,3),\n",
    "     (1,3),\n",
    "#       (1,3)\n",
    "    ]\n",
    "# y: element i is a label for ith document\n",
    "y = [0, 0, 1, 1] # , 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEPCAYAAABGP2P1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1141ee2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the data. \n",
    "# Red means class 0, blue means class 1.\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_data(X, y):\n",
    "    \"\"\" Assumes 2-d data. \"\"\"\n",
    "    plt.figure()\n",
    "    for xi, yi in zip(X, y):\n",
    "        color = 'r' if yi == 0 else 'b'\n",
    "        plt.plot(xi[0], xi[1], color + 'o', ms=20)\n",
    "    plt.xlabel('feature 0')\n",
    "    plt.ylabel('feature 1')\n",
    "    plt.xlim((-1,2))\n",
    "    plt.ylim((-1, 4))\n",
    "    plt.annotate('class 0', xy=(1.2, 0), color='r', size=15)\n",
    "    plt.annotate('class 1', xy=(1.2, 3), color='b', size=15)\n",
    "    plt.show()\n",
    "    \n",
    "plot_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Simplest machine learning algorithm:\n",
    "\n",
    "class SimplestMachine:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.f = dict()\n",
    "\n",
    "    def train(self, X, y):\n",
    "        for xi, yi in zip(X, y):\n",
    "          self.f[xi] = yi\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.f[x]\n",
    "\n",
    "# What does this do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred\ttruth\n",
      " 0\t0\n",
      "0\t0\n",
      "1\t1\n",
      "1\t1\n"
     ]
    }
   ],
   "source": [
    "simplest_machine = SimplestMachine()\n",
    "simplest_machine.train(X, y)\n",
    "predictions = [simplest_machine.predict(xi) for xi in X]\n",
    "print('pred\\ttruth\\n', '\\n'.join('%d\\t%d' % (p, yi) for p, yi in zip(predictions, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "(0, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-9cba31281ef1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# What does it do for unseen example?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msimplest_machine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-55d614d1ae88>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# What does this do?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (0, 4)"
     ]
    }
   ],
   "source": [
    "# What does it do for unseen example?\n",
    "simplest_machine.predict((0, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Second simplest machine learning algorithm:\n",
    "import numpy as np\n",
    "\n",
    "class SimpleMachine:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.f = dict()\n",
    "\n",
    "    def train(self, X, y):\n",
    "        for xi, yi in zip(X, y):\n",
    "          self.f[xi] = yi\n",
    "\n",
    "    def predict(self, x):\n",
    "        x_closest = self.find_most_similar(x)\n",
    "        return self.f[x_closest]\n",
    "    \n",
    "    def find_most_similar(self, x):\n",
    "        best_idx = np.argmin([self.distance(x, xi) \n",
    "                              for xi in self.f.keys()])\n",
    "        print('closest match is', list(self.f.keys())[best_idx])\n",
    "        return list(self.f.keys())[best_idx]\n",
    "\n",
    "    def distance(self, x, xi):\n",
    "        return np.sqrt(np.sum((np.array(x)-np.array(xi))**2))\n",
    "        \n",
    "# What does this do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c32985842a8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msimple_machine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimpleMachine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msimple_machine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msimple_machine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mxi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pred\\ttruth\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%d\\t%d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "simple_machine = SimpleMachine()\n",
    "simple_machine.train(X, y)\n",
    "predictions = [simple_machine.predict(xi) for xi in X]\n",
    "print('pred\\ttruth\\n', '\\n'.join('%d\\t%d' % (p, yi) for p, yi in zip(predictions, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# What does it do for unseen example?\n",
    "simple_machine.predict((0, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='images/knn.png' width='80%'/>\n",
    "\n",
    "<http://www.scholarpedia.org/article/K-nearest_neighbor>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Generalization\n",
    "\n",
    "How accurate will I be on a new, unobserved example?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How do you know if it works?\n",
    "\n",
    "1. Train on data ${\\mathcal D_1}$\n",
    "2. Predict on data ${\\mathcal D_2}$\n",
    "3. Compute accuracy on ${\\mathcal D_2}$.\n",
    "   - Why not ${\\mathcal D_1}$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How do you know if it works?\n",
    "\n",
    "1. Train on data ${\\mathcal D_1}$\n",
    "2. Predict on data ${\\mathcal D_2}$\n",
    "3. Compute accuracy on ${\\mathcal D_2}$.\n",
    "4. Tweak algorithm / representation\n",
    "5. Repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How do you know if it works?\n",
    "\n",
    "1. Train on data ${\\mathcal D_1}$\n",
    "2. Predict on data ${\\mathcal D_2}$\n",
    "3. Compute accuracy on ${\\mathcal D_2}$.\n",
    "4. Tweak algorithm / representation\n",
    "5. Repeat\n",
    "\n",
    "How many times can I do this?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Measuring Generalization\n",
    "\n",
    "- Cross-validation\n",
    "  - train on 90%, test on 10%, repeat 10 x's\n",
    "        - each example appears only once in test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Experimental Design\n",
    "\n",
    "1. Collect data\n",
    "2. Build model\n",
    "3. Compute cross-validation accuracy\n",
    "4. Tune model\n",
    "5. Repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Experimental Design\n",
    "\n",
    "1. Collect data\n",
    "2. Build model\n",
    "3. Compute cross-validation accuracy\n",
    "4. Tune model\n",
    "5. Repeat\n",
    "6. **Report accuracy on new data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "- What is overfitting? How do you know it is happening? How do you fix?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='images/biasvariance.png' width='70%'/>\n",
    "\n",
    "<http://scott.fortmann-roe.com/docs/BiasVariance.html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Machine Learning for Sentiment Analysis\n",
    "\n",
    "1. Collect data: E.g., <http://help.sentiment140.com/for-students>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Download Twitter data labeled by sentiment.\n",
    "\n",
    "import zipfile\n",
    "from urllib.request import urlretrieve\n",
    "# The file is 78M, so this will take a while.\n",
    "url = urlretrieve('http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip', 'data.zip')\n",
    "zfile = zipfile.ZipFile('data.zip')\n",
    "zfile.extractall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We'll focus on the smaller file that was manually labeled.\n",
    "# The larger file has 1.6M tweets \"pseudo-labeled\" using emoticons\n",
    "tweet_file = open('testdata.manual.2009.06.14.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"4\",\"3\",\"Mon May 11 03:17:40 UTC 2009\",\"kindle2\",\"tpryan\",\"@stellargirl I loooooooovvvvvveee my Kindle2. Not that the DX is cool, but the 2 is fantastic in its own right.\"\r\n"
     ]
    }
   ],
   "source": [
    "# show a positive example.\n",
    "!egrep '\\\"4' testdata.manual.2009.06.14.csv | head -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"0\",\"219\",\"Mon May 25 17:31:43 UTC 2009\",\"exam\",\"enriquenieto\",\"I hate revision, it's so boring! I am totally unprepared for my exam tomorrow :( Things are not looking good...\"\r\n"
     ]
    }
   ],
   "source": [
    "# show a negative example.\n",
    "!egrep '\\\"0' testdata.manual.2009.06.14.csv | head -35 | tail -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"2\",\"13\",\"Mon May 11 03:32:42 UTC 2009\",\"obama\",\"jpeb\",\"Check this video out -- President Obama at the White House Correspondents' Dinner http://bit.ly/IMXUM\"\r\n"
     ]
    }
   ],
   "source": [
    "# show a neutral example.\n",
    "!egrep '\\\"2' testdata.manual.2009.06.14.csv | head -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 498 tweets\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "file_reader = csv.reader(tweet_file, delimiter=',', quotechar='\"')\n",
    "tweets = []\n",
    "for row in file_reader:\n",
    "    tweets.append({'label': int(row[0]),\n",
    "                   'text': row[5]})\n",
    "tweets = np.array(tweets)\n",
    "print('read %d tweets' % len(tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label counts= Counter({4: 182, 0: 177, 2: 139})\n"
     ]
    }
   ],
   "source": [
    "# Create label vector (y) and print its stats.\n",
    "from collections import Counter\n",
    "y = np.array([t['label'] for t in tweets])\n",
    "print('label counts=', Counter(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorized 498 tweets. found 2264 terms.\n"
     ]
    }
   ],
   "source": [
    "# Create feature vectors (X) from text strings.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(min_df=1)\n",
    "X = vectorizer.fit_transform(t['text'] for t in tweets)\n",
    "print('vectorized %d tweets. found %d terms.' % (X.shape[0], X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<498x2264 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 6422 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is X?\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x2264 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 16 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data: non-zero values.\n",
    "X[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1876, 1199, 1337, 1119, 1393, 1960, 1961,  652, 1060,  501,  362,\n",
       "        737, 1021, 1064, 1458, 1669], dtype=int32)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indices: index of non-zero values.\n",
    "X[0].indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '000', '04fo', ..., 'zomg', 'zoom', 'zydrunas'], \n",
       "      dtype='<U40')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which terms correspond to which columns?\n",
    "vocab = np.array(vectorizer.get_feature_names())\n",
    "vocab\n",
    "# vocab is ordered by column index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['stellargirl', 'loooooooovvvvvveee', 'my', 'kindle2', 'not', 'that',\n",
       "       'the', 'dx', 'is', 'cool', 'but', 'fantastic', 'in', 'its', 'own',\n",
       "       'right'], \n",
       "      dtype='<U40')"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So, non-zero terms in first row are:\n",
    "vocab[X[0].indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 4, 'text': '@stellargirl I loooooooovvvvvveee my Kindle2. Not that the DX is cool, but the 2 is fantastic in its own right.'}\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# Double-check:\n",
    "print(tweets[0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_indices= [1961 1998  988 ..., 1363 1364    0]\n",
      "top_terms:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('the', 1961),\n",
       " ('to', 1998),\n",
       " ('http', 988),\n",
       " ('is', 1060),\n",
       " ('and', 152),\n",
       " ('at', 209),\n",
       " ('it', 1062),\n",
       " ('for', 790),\n",
       " ('my', 1337),\n",
       " ('of', 1416)]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are the most frequent terms?\n",
    "# Sum columns:\n",
    "col_sums = X.sum(axis=0).A1\n",
    "# Sort sums in descending order, and return the indices.\n",
    "top_indices = np.argsort(col_sums)[::-1]\n",
    "print('top_indices=', top_indices)\n",
    "top_terms = vocab[top_indices]\n",
    "print('top_terms:')\n",
    "list(zip(top_terms, top_indices))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "2.) Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a LogisticRegression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict on training data.\n",
    "predicted = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training data=0.996\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracy\n",
    "def accuracy(truth, predicted):\n",
    "    return (len([1 for tr, pr in zip(truth, predicted) if tr == pr]) / len(truth))\n",
    "\n",
    "print('accuracy on training data=%.3f' % accuracy(y, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2264)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model inspection:\n",
    "# Logistic regression has one real-valued parameter for each (feature, class) pair\n",
    "model.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.11694478, -0.04422996, -0.04308365, ...,  0.25238453,\n",
       "       -0.13221204,  0.1750897 ])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weights for the positive class.\n",
    "model.coef_[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top weighted terms for positive class:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('awesome', 1.5207939804767958),\n",
       " ('love', 1.5080417103616175),\n",
       " ('g2', 1.2252868549798153),\n",
       " ('good', 1.1735868088945105),\n",
       " ('kindle2', 1.0349501613531902),\n",
       " ('lebron', 0.953648523997499),\n",
       " ('great', 0.88798751556470601),\n",
       " ('mcdonalds', 0.81454565648964972),\n",
       " ('tonight', 0.80216396607369378),\n",
       " ('mashable', 0.8002958584312525)]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are the top weighted features?\n",
    "# Get the learned coefficients for the Positive class.\n",
    "coef = model.coef_[2]\n",
    "# Sort them in descending order.\n",
    "top_coef_ind = np.argsort(coef)[::-1]\n",
    "# Get the names of those features.\n",
    "top_coef_terms = vocab[top_coef_ind]\n",
    "# Get the weights of those features\n",
    "top_coef = coef[top_coef_ind]\n",
    "# Print the top 10.\n",
    "print('top weighted terms for positive class:')\n",
    "list(zip(top_coef_terms, top_coef))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top weighted terms for negative class:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('warner', 1.5575574474701563),\n",
       " ('hate', 1.2898069199262512),\n",
       " ('aig', 1.2761967996219201),\n",
       " ('gm', 1.0826104425890997),\n",
       " ('korea', 1.061361439980635),\n",
       " ('north', 1.061361439980635),\n",
       " ('not', 1.0523889298079891),\n",
       " ('cheney', 0.93733227107412254),\n",
       " ('that', 0.89150593439290238),\n",
       " ('fail', 0.8883378090677998)]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the learned coefficients for the Negative class.\n",
    "coef = model.coef_[0]\n",
    "# Sort them in descending order.\n",
    "top_coef_ind = np.argsort(coef)[::-1]\n",
    "# Get the names of those features.\n",
    "top_coef_terms = vocab[top_coef_ind]\n",
    "# Get the weights of those features\n",
    "top_coef = coef[top_coef_ind]\n",
    "# Print the top 10.\n",
    "print('top weighted terms for negative class:')\n",
    "list(zip(top_coef_terms, top_coef))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average 5-fold cross validation accuracy=0.67 (std=0.04)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.64, 0.73, 0.64, 0.7070707070707071, 0.6565656565656566]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5-fold Cross-validation accuracy\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "cv = KFold(len(y), 5)\n",
    "accuracies = []\n",
    "for train_ind, test_ind in cv:\n",
    "    model.fit(X[train_ind], y[train_ind])  # select just the training instances.\n",
    "    predictions = model.predict(X[test_ind])\n",
    "    accuracies.append(accuracy(y[test_ind], predictions))\n",
    "    \n",
    "print('Average 5-fold cross validation accuracy=%.2f (std=%.2f)' %\n",
    "      (np.mean(accuracies), np.std(accuracies)))\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Error analysis\n",
    "train_ind = range(400)\n",
    "test_ind = range(401, len(y))\n",
    "model.fit(X[train_ind], y[train_ind])\n",
    "predictions = model.predict(X[test_ind])\n",
    "probabilities = model.predict_proba(X[test_ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97, 3)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.90011587401933302,\n",
       "  {'label': 2,\n",
       "   'text': \"Missed this insight-filled May column: One smart guy looking closely at why he's impressed with Kindle2 http://bit.ly/i0peY @wroush\"}),\n",
       " (0.89912680669429568,\n",
       "  {'label': 2,\n",
       "   'text': 'all about Ajax,jquery ,css ,JavaScript and more... (many examples) http://ajaxian.com/'}),\n",
       " (0.88987977036981047,\n",
       "  {'label': 2, 'text': '@johncmayer is Bobby Flay joining you?'}),\n",
       " (0.84758629612195957,\n",
       "  {'label': 2,\n",
       "   'text': \"I'm truly braindead.  I couldn't come up with Warren Buffet's name to save my soul\"}),\n",
       " (0.83704045706422547,\n",
       "  {'label': 0,\n",
       "   'text': \"Shit's hitting the fan in Iran...craziness indeed #iranelection\"}),\n",
       " (0.8299469087138438,\n",
       "  {'label': 4,\n",
       "   'text': \"I'd say some sports writers are idiots for saying Roger Federer is one of the best ever in Tennis.  Roger Federer is THE best ever in Tennis\"}),\n",
       " (0.82949753197299936,\n",
       "  {'label': 0,\n",
       "   'text': 'I still love my Kindle2 but reading The New York Times on it does not feel natural. I miss the Bloomingdale ads.'}),\n",
       " (0.81068475446644173, {'label': 0, 'text': 'Fighting with LaTex. Again...'}),\n",
       " (0.75401849722796177,\n",
       "  {'label': 4,\n",
       "   'text': \"reading Michael Palin book, The Python Years...great book. I also recommend Warren Buffet &amp; Nelson Mandela's bio\"}),\n",
       " (0.7503315860444123,\n",
       "  {'label': 0,\n",
       "   'text': \"I can't watch TV without a Tivo.  And after all these years, the Time/Warner DVR  STILL sucks. http://www.davehitt.com/march03/twdvr.html\"})]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# P(y=y_k | x)\n",
    "# What are most probable positives?\n",
    "prob_pos = probabilities[:,2]  # get 3rd column == pos\n",
    "topi = np.argsort(prob_pos)[::-1][:10]\n",
    "list(zip(prob_pos[topi], tweets[400:][topi]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.90011587401933302, {'label': 4, 'text': 'is scrapbooking with Nic =D'}),\n",
       " (0.89912680669429568,\n",
       "  {'label': 0, 'text': 'cant sleep... my tooth is aching.'}),\n",
       " (0.88987977036981047,\n",
       "  {'label': 0,\n",
       "   'text': \"North Korea, please cease this douchebaggery. China doesn't even like you anymore. http://bit.ly/NeHSl\"}),\n",
       " (0.84758629612195957, {'label': 0, 'text': \"ShaunWoo hate'n on AiG\"}),\n",
       " (0.83704045706422547,\n",
       "  {'label': 2,\n",
       "   'text': 'New blog post: Harvard Versus Stanford - Who Wins? http://bit.ly/MCoCo'}),\n",
       " (0.8299469087138438,\n",
       "  {'label': 0,\n",
       "   'text': 'annoying new trend on the internets:  people picking apart michael lewis and malcolm gladwell.  nobody wants to read that.'}),\n",
       " (0.82949753197299936,\n",
       "  {'label': 2,\n",
       "   'text': 'Bill Simmons in conversation with Malcolm Gladwell http://bit.ly/j9o50'}),\n",
       " (0.81068475446644173,\n",
       "  {'label': 4,\n",
       "   'text': 'SHOUT OUTS TO ALL EAST PALO ALTO FOR BEING IN THE BUILDIN KARIZMAKAZE 50CAL GTA! ALSO THANKS TO PROFITS OF DOOM UNIVERSAL HEMPZ CRACKA......'}),\n",
       " (0.75401849722796177,\n",
       "  {'label': 4,\n",
       "   'text': '@YarnThing you will not regret going to see Star Trek. It was AWESOME!'}),\n",
       " (0.7503315860444123,\n",
       "  {'label': 2, 'text': 'Going to see star trek soon with my dad.'})]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are most probable negatives?\n",
    "prob_neg = probabilities[:,2]  # get 1st column == neg\n",
    "topi = np.argsort(prob_neg)[::-1][:10]\n",
    "list(zip(prob_neg[topi], tweets[:400][topi]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what 67% accuracy looks like!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Midterm Review\n",
    "\n",
    "**Problem types:**\n",
    "\n",
    "- Algorithm output\n",
    "  - e.g., score documents according to X\n",
    "  - levenshtein distance\n",
    "  - skip-lists\n",
    "  - tokenize/stem\n",
    "  - evaluation\n",
    "\n",
    "\n",
    "- Algorithm invention\n",
    "  - I give you code, and I ask you to change it\n",
    "  - E.g., modify tf-idf to prefer newer documents \n",
    "\n",
    "\n",
    "- Efficiency / Analysis of algorithm\n",
    "  - I give you algorithm, you tell me how to make it more more efficient/more accurate\n",
    "  - E.g., $n^2$ -> $n$\n",
    "\n",
    "\n",
    "- True/False (10%)\n",
    "\n",
    "\n",
    "\n",
    "**Topics:**\n",
    "\n",
    "- Indexing\n",
    "  - type/token/term\n",
    "  - tokenization\n",
    "  - lemmatization\n",
    "  - stemming\n",
    "  - stopping\n",
    "\n",
    "\n",
    "- efficient query processing\n",
    "  - and\n",
    "  - or\n",
    "  - not\n",
    "  - phrases\n",
    "  - skip lists\n",
    "\n",
    "\n",
    "- spelling correction\n",
    "  - levenshtein\n",
    "\n",
    "\n",
    "\n",
    "- Zipf\n",
    "\n",
    "- Heap\n",
    "\n",
    "\n",
    "- Ranking\n",
    "  - tf\n",
    "  - idf\n",
    "  - approximate k-best\n",
    "    - champion list\n",
    "    - cluster pruning\n",
    "  - field search\n",
    "  - Binary Independence Model\n",
    "  - BM25\n",
    "  - cosine similarity\n",
    "  - language model\n",
    "    - smoothing / interpolation\n",
    "  - cosine similarity vs euclidean distance\n",
    "  - Relevance feedback\n",
    "\n",
    "- Evaluation\n",
    "  - precision\n",
    "  - recall\n",
    "  - f1\n",
    "  - precision/recall curve\n",
    "  - Mean Average Precision\n",
    "\n",
    "- Formulae you should know:\n",
    " - precision, recall\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
