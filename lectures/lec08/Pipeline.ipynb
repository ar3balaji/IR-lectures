{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CS 429: Information Retrieval\n",
    "\n",
    "<br>\n",
    "\n",
    "## Lecture 8: Scalable scoring and system integration\n",
    "\n",
    "<br>\n",
    "\n",
    "### Dr. Aron Culotta\n",
    "### Illinois Institute of Technology \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Last time:\n",
    "\n",
    " - tf-idf weights for each document\n",
    " - Vector Space Model\n",
    " - Cosine Similarity\n",
    "\n",
    "Today:\n",
    "\n",
    " - How to efficiently retrieve top ranked documents\n",
    " - Full search pipeline\n",
    " - Grab bag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**tf-idf weight:**\n",
    "\n",
    "- $w_{t,d} = (1 + \\log tf_{t,d}) \\times \\log (\\frac{N}{df_t})$\n",
    "\n",
    "**cosine similarity:**\n",
    "\n",
    "$sim(a, b) = \\frac{a \\cdot b}{||a||\\hbox{ } ||b||}$\n",
    "\n",
    "- $a \\cdot b$ is dot product: $\\sum_i a_i \\times b_i$\n",
    "\n",
    "\n",
    "- $||a||$ is norm: $\\sqrt{\\sum_i a_i^2}$\n",
    "\n",
    "**search:**\n",
    "\n",
    "- convert each query and document into *tf-idf* vectors $q$ and $d$\n",
    "- sort documents by $sim(q, d)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 118.37), (1, 52.15)]\n"
     ]
    }
   ],
   "source": [
    "# Score documents by cosine similarity\n",
    "from collections import defaultdict\n",
    "\n",
    "# tf-idf weighted query\n",
    "query = {'the': 0.01, 'zygote': 14.2}\n",
    "\n",
    "# index is list of (doc_id, tf-idf weight) pairs\n",
    "index = {'the': [(0, 44), (1, 100)],\n",
    "         'zygote': [(0, 100), (1, 44)]}\n",
    "\n",
    "# document lengths, for normalization\n",
    "doc_lengths = {0: 12, 1: 12}\n",
    "\n",
    "def cosine(query, index, doc_lengths):\n",
    "    scores = defaultdict(lambda: 0)\n",
    "    # For each search term\n",
    "    for query_term, query_weight in query.items():\n",
    "        # For each matching doc\n",
    "        for doc_id, doc_weight in index[query_term]:\n",
    "            scores[doc_id] += query_weight * doc_weight  # part of dot product\n",
    "\n",
    "    # normalize by doc length (why not also by query length?)\n",
    "    for doc_id in scores:\n",
    "        scores[doc_id] /= doc_lengths[doc_id]\n",
    "    return sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "results = cosine(query, index, doc_lengths)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What is runtime?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$O(QN)$ where $Q$ is number of query terms and $N$ is number of documents containing each query term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Faster Cosine Search\n",
    "\n",
    "If only retrieving top $k$, how can we do better than \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "return sorted(scores.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "No need to sort all scores: use priority queue of size $k$\n",
    "\n",
    "- $O(2J)$ to construct heap, where $J$ is number of docs with non-zero score\n",
    "- $O(k \\log J)$ to find top $k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Approximate $k$-best\n",
    "\n",
    "- How can we find *almost* the top $k$ documents?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Idea:**\n",
    "  - Find a set $A$ of *contenders* $K < |A| << N$\n",
    "  - Only compute cosine similarity between query and $A$\n",
    "  \n",
    "We'll consider a number of approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Only use high $idf$ terms\n",
    "\n",
    "- Similar to pruning stop words\n",
    "- Since low $idf$ terms occur in many documents, this prunes a lot\n",
    "- What's the downside?\n",
    "\n",
    "<br><br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Soft conjunction\n",
    "\n",
    "- If query has 4 terms\n",
    "  - Retrieve all docs that match at least 3 terms\n",
    "  - Compute cosine similarity for this subset\n",
    "- How to find matches efficiently?\n",
    "\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Champion lists\n",
    "\n",
    "At index time:\n",
    "\n",
    "- For each term $t$\n",
    "  - compute $r$ documents that have highest weight for $t$ (\"champion lists\")\n",
    "  \n",
    "At query time:\n",
    "\n",
    "- Take union of champion lists of all query terms\n",
    "- Sort them by cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- How can we use an inverted index for a champion lists?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# index is list of (doc_id, tf-idf weight) pairs\n",
    "index = {'the': [(0, 44), (1, 100), (2, 50)],\n",
    "         'zygote': [(0, 100), (1, 44), (2, 10)]}\n",
    "\n",
    "# If using 2 champions, this becomes:\n",
    "\n",
    "champ_index = {'the': [(1, 100), (2, 50)],\n",
    "             'zygote': [(0, 100), (1, 44)]}\n",
    "\n",
    "champ_index2 = {'the': [1, 2],\n",
    "                'zygote': [0, 1]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Static quality scores\n",
    "\n",
    "- Assign a score $g(d)$ to each document at index time indicating how good it is\n",
    "- Based on what?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- List of known good pages (Wikipedia, CNN, ...)\n",
    "- Pages with many in-links, bookmarks\n",
    "- PageRank\n",
    "- Is it spam?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Static quality scores\n",
    "\n",
    "- How to combine static score with cosine score?\n",
    "  - **addition**: `netscore`$(q,d) = g(d) + sim(q,d)$\n",
    "  \n",
    "- How to efficiently find top $k$ by `netscore`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- One speedup: Order postings lists by $g(d)$\n",
    "  - Thus, we'll find top documents earlier\n",
    "  - Good if have small time budget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impact ordering\n",
    "\n",
    "- Sort postings list in decreasing order of $tfidf$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index = {'the': [(0, 44), (1, 100)],\n",
    "         'zygote': [(0, 100), (1, 44)]}\n",
    "\n",
    "# becomes\n",
    "\n",
    "index = {'the': [(1, 100), (0, 44)],\n",
    "         'zygote': [(0, 100), (1, 44)]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does this affect our algorithm to merge postings lists?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We'll instead use our initial algorithm that accumulates scores one term at a time.\n",
    "\n",
    "- Approximations:\n",
    "  - **Early termination**: stop traversing postings after $r$ docs or when weight drops below a threshold\n",
    "  - **$idf$ ordered search terms**: Sort query terms by $idf$ and process in order. Stop if score doesn't change much with additional term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster pruning\n",
    "\n",
    "![cluster](files/cluster.png)\n",
    "\n",
    "- pick $\\sqrt(N)$ docs at random (**leaders**)\n",
    "- assign all other docs to nearest leader\n",
    "- **follower**: doc attached to a leader\n",
    "- for query Q\n",
    "  - find nearest leader\n",
    "  - find K-best followers\n",
    "  - rank by cosine similarity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Improvements?\n",
    "\n",
    "- Select $b > 1$ leaders; attach each follower to $c > 1$ leaders\n",
    "- when will cluster pruning fail?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tiered indices\n",
    "\n",
    "![tier](files/tier.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Field and Zone Search\n",
    "\n",
    "- *Field:* year, name, etc (limited values)\n",
    "- *Zone:* subsection of document (abstract, footer)\n",
    "\n",
    "How to search these efficiently?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "index = {'the': [(0, 44), (1, 100)],\n",
    "         'zygote': [(0, 100), (1, 44)],\n",
    "         'the-title': [(0, 44), (1, 100)],\n",
    "         'zygote-title': [(0, 100), (1, 44)],\n",
    "         'the-abstract': [(0, 44), (1, 100)],\n",
    "         'zygote-abstract': [(0, 100), (1, 44)],\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query term proximity\n",
    "\n",
    "- If query is: *dog catcher van*, how can we prefer documents where the three words occur in proximity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query parser\n",
    "\n",
    "- Consider phrase query \"pitchfork music festival\"\n",
    "- Submit various queries until get at least $k$ results\n",
    " - \"pitchfork music festival\"\n",
    " - \"pitchform music\" AND \"music festival\"\n",
    " - pitchform AND music AND festival\n",
    " - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All together now...\n",
    "\n",
    "![system](files/system.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
