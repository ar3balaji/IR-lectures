{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CS 429: Information Retrieval\n",
    "<br>\n",
    "\n",
    "## Lecture 13: Language Models\n",
    "\n",
    "<br>\n",
    "\n",
    "### Dr. Aron Culotta\n",
    "### Illinois Institute of Technology\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Language Models\n",
    "\n",
    "**Idea:**\n",
    "\n",
    "Rank documents by:\n",
    "\n",
    "$P(q|d)$\n",
    "\n",
    "The probability that the process that generated $d$ would also generate $q$.\n",
    "\n",
    "No variable for relevance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Generative models\n",
    "- Each document is a list of strings from a language.\n",
    "- Consider all the possible documents the author could have written\n",
    "  - How many of them would contain the term \"zebra\"?\n",
    "- Consider the query $q$\n",
    "  - What is the probability that the author of document $d$ would have written down $q$?\n",
    "  - $P(q|M_d)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Finite State Machine\n",
    "\n",
    "Let a *language* $L$ be a set of documents $\\{d_1 \\ldots d_n\\}$.\n",
    "\n",
    "A finite-state machine $M_L$ accepts a document $d$ as input and outputs \"yes\" if $d \\in L$; otherwise it outputs \"no.\"\n",
    "\n",
    "$M_L$ consists of:\n",
    "\n",
    "- a set of **states** $S = \\{s_1 \\ldots s_m\\}$\n",
    "- an input **vocabulary** $V$, a finite set of acceptable terms\n",
    "- a **transition function** $\\delta : V \\times S \\mapsto S$ \n",
    "  - When in state $s_i$, if term $w \\in V$ is read, the state changes to $s_j$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"files/fsm.png\" width=\"50%\"/>\n",
    "\n",
    "\n",
    "- <font color=\"green\">Mr. John Smith Jr.</font> &nbsp;&nbsp; start $\\rightarrow$ prefix $\\xrightarrow{Mr.}$ first $\\xrightarrow{John}$ last $\\xrightarrow{Smith}$ suffix $\\xrightarrow{Jr.}$ accept\n",
    "- <font color=\"green\">Jane Doe</font>\n",
    "- <font color=\"red\">Mr. Jr.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Weighted Finite State Machine\n",
    "\n",
    "<img src=\"files/wfsm.png\" width=\"50%\"/>\n",
    "\n",
    "\n",
    "- $P($<font color=\"green\">Mr. John Smith Jr.</font>$)= 0.4 * 1.0 * 1.0 * .05 * 1.0 = 0.02$ \n",
    "- $P($<font color=\"green\">Jane Doe</font>$) = 0.6 * 1.0 * 0.95 = 0.57$\n",
    "- $P($<font color=\"red\">Mr. Jr.</font>$) = 0.0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Generative Model\n",
    "\n",
    "Rather than simply assigning probabilities to documents, we can use a weighted finite state machine to **generate** documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jesse Smith \n",
      "John Doe III \n",
      "Jane Jones \n",
      "Jane Jones \n",
      "Jesse Jones \n",
      "Mrs. Jane Smith \n",
      "Dr. Jesse Smith \n",
      "Jane Smith \n",
      "Dr. Jane Smith \n",
      "Mrs. John Jones \n",
      "Jesse Jones \n",
      "John Doe \n",
      "John Jones \n",
      "John Doe \n",
      "Jane Doe \n",
      "Jesse Jones \n",
      "Dr. Jesse Jones \n",
      "Ms. Jesse Smith \n",
      "John Smith \n",
      "John Doe \n"
     ]
    }
   ],
   "source": [
    "# Generate names.\n",
    "# Assume all words are equally likely, but state transitions follow previous FSM.\n",
    "\n",
    "prefixes = ['Mr. ', 'Ms. ', 'Mrs. ', 'Dr. ']\n",
    "firsts = ['John ', 'Jane ', 'Jesse ']\n",
    "lasts = ['Smith ', 'Jones ', 'Doe ']\n",
    "suffixes = ['Jr. ', 'Sr. ', 'III ']\n",
    "\n",
    "def sample(alist):\n",
    "    \"\"\" Sample an element of a list. \"\"\"\n",
    "    return alist[random.randint(0, len(alist) - 1)]\n",
    "\n",
    "import random\n",
    "num_documents = 20\n",
    "for i in range(num_documents):\n",
    "    doc = ''\n",
    "    if random.random() <= 0.4:  # prefix\n",
    "        doc += sample(prefixes)\n",
    "    doc += sample(firsts) + sample(lasts)\n",
    "    if random.random() <= .05:  # suffix\n",
    "        doc += sample(suffixes)\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Language Model\n",
    "\n",
    "A weighted finite state machine that can\n",
    "\n",
    "- generate documents\n",
    "- generate queries\n",
    "- assign probabilities to documents/queries\n",
    "\n",
    "\n",
    "**Idea:**\n",
    "\n",
    "- Construct a language model $M_d$ for each document $d$.\n",
    "- For each query $q$, compute the probability that $M_d$ generated $q$: $P(q|M_d)$\n",
    "- Rank documents by $P(q|M_d)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"files/lm2.png\" width=\"50%\"/>\n",
    "\n",
    "**How can we construct a language model from a document?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Long history in natural language processing:\n",
    "\n",
    "- parse trees\n",
    "\n",
    "![parse](files/parse.jpg)\n",
    "\n",
    "Source: [Wikipedia](http://en.wikipedia.org/wiki/Parse_tree)\n",
    "\n",
    "- [sentence generators](http://writing-program.uchicago.edu/toys/randomsentence/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "But, grammar has little effect on information retrieval.\n",
    "\n",
    "- queries are rarely grammatical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Unigram Language Models\n",
    "\n",
    "- Ignore word order.\n",
    "- Generate each word independently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\\begin{align} P(q|M_d) = \\prod_{t \\in q} P(t|M_d) = \\prod_{t \\in q} \\frac{tf_{t, d}}{L_d} \\end{align}$\n",
    "\n",
    "- $q:$ query consisting of terms $t$\n",
    "- $M_d:$ language model for document $d$\n",
    "- $tf_{t, d}:$ frequency of term $t$ in document $d$\n",
    "- $L_d:$ number of tokens in $d$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Unigram Language Models\n",
    "\n",
    "<img src=\"files/uni.png\" width=\"50%\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'gold': 0.1,\n",
       "         'in': 0.1,\n",
       "         'medals': 0.1,\n",
       "         'nine': 0.1,\n",
       "         'olympics': 0.1,\n",
       "         'states': 0.1,\n",
       "         'the': 0.2,\n",
       "         'united': 0.1,\n",
       "         'won': 0.1})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def doc2model(doc):\n",
    "    \"\"\" Convert a document d into a language model M_d. \"\"\"\n",
    "    counts = Counter(doc)\n",
    "    for term in counts:\n",
    "        counts[term] /= 1. * len(doc)\n",
    "    return counts\n",
    "\n",
    "m_d = doc2model(['the', 'united', 'states', 'won', 'nine', 'gold', 'medals', 'in', 'the', 'olympics'])\n",
    "m_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20, 13, 67]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sampling from a multinomial\n",
    "import numpy as np\n",
    "np.random.multinomial(100, [.2, .2, .6], size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in',\n",
       " 'olympics',\n",
       " 'olympics',\n",
       " 'the',\n",
       " 'medals',\n",
       " 'medals',\n",
       " 'nine',\n",
       " 'united',\n",
       " 'won',\n",
       " 'states']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sample_from_model(m_d, length):\n",
    "    \"\"\" Sample length words from language model m_d. \"\"\"\n",
    "    counts = np.random.multinomial(length, list(m_d.values()), size=1)[0]\n",
    "    words = []\n",
    "    for i, count in enumerate(counts):\n",
    "        words.extend(count * [list(m_d.keys())[i]])\n",
    "    return words\n",
    "    \n",
    "sample_from_model(m_d, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pr([the, olympics] | d)=0.020\n",
      "Pr([united, states] | d)=0.010\n",
      "Pr([olympics, united, states] | d)=0.001\n"
     ]
    }
   ],
   "source": [
    "def pr_q_given_m(q, m_d):\n",
    "    \"\"\" Compute P(q|M_d), the probability of language model M_d generating query q. \"\"\"\n",
    "    product = 1.\n",
    "    for qi in q:\n",
    "        product *= m_d[qi]\n",
    "    return product\n",
    "\n",
    "print('Pr([the, olympics] | d)=%.3f' % pr_q_given_m(['the', 'olympics'], m_d))\n",
    "print('Pr([united, states] | d)=%.3f' % pr_q_given_m(['united', 'states'], m_d))\n",
    "print('Pr([olympics, united, states] | d)=%.3f' % pr_q_given_m(['olympics', 'united', 'states'], m_d))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m_d2:\n",
      "Counter({'united states': 0.1111111111111111,\n",
      "         'gold medals': 0.1111111111111111,\n",
      "         'states won': 0.1111111111111111,\n",
      "         'in the': 0.1111111111111111,\n",
      "         'the united': 0.1111111111111111,\n",
      "         'the olympics': 0.1111111111111111,\n",
      "         'medals in': 0.1111111111111111,\n",
      "         'won nine': 0.1111111111111111,\n",
      "         'nine gold': 0.1111111111111111})\n",
      "\n",
      "m_d3\n",
      "Counter({'in the': 0.16666666666666666,\n",
      "         'slalom in': 0.08333333333333333,\n",
      "         'united states': 0.08333333333333333,\n",
      "         'gold medals': 0.08333333333333333,\n",
      "         'the slalom': 0.08333333333333333,\n",
      "         'states won': 0.08333333333333333,\n",
      "         'the united': 0.08333333333333333,\n",
      "         'the olympics': 0.08333333333333333,\n",
      "         'medals in': 0.08333333333333333,\n",
      "         'won nine': 0.08333333333333333,\n",
      "         'nine gold': 0.08333333333333333})\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "def doc2ngram_model(doc, n):\n",
    "    \"\"\" Convert a document d into a language model M_d. \"\"\"\n",
    "    counts = Counter()\n",
    "    for i in range(len(doc) - 1):\n",
    "        counts.update([' '.join(doc[i:i+n]) for i in range(len(doc) - n + 1)])\n",
    "    length = sum(counts.values())\n",
    "    for term in counts:\n",
    "        counts[term] /= 1. * length\n",
    "    return counts\n",
    "\n",
    "m_d2 = doc2ngram_model(['the', 'united', 'states', 'won', 'nine', 'gold', 'medals', 'in', 'the', 'olympics'], 2)\n",
    "m_d3 = doc2ngram_model(['the', 'united', 'states', 'won', 'nine', 'gold', 'medals', 'in', 'the', 'slalom', 'in', 'the', 'olympics'], 2)\n",
    "\n",
    "print('m_d2:') \n",
    "pprint(m_d2)\n",
    "\n",
    "print('\\nm_d3')\n",
    "pprint(m_d3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['slalom in',\n",
       " 'gold medals',\n",
       " 'gold medals',\n",
       " 'states won',\n",
       " 'in the',\n",
       " 'the united',\n",
       " 'the united',\n",
       " 'the olympics',\n",
       " 'won nine',\n",
       " 'nine gold']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_from_model(m_d3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nine gold medals in',\n",
       " 'nine gold medals in',\n",
       " 'united states won nine',\n",
       " 'united states won nine',\n",
       " 'united states won nine',\n",
       " 'united states won nine',\n",
       " 'the united states won',\n",
       " 'states won nine gold',\n",
       " 'states won nine gold',\n",
       " 'won nine gold medals']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_d4 = doc2ngram_model(['the', 'united', 'states', 'won', 'nine', 'gold', 'medals', 'in', 'the', 'olympics'], 4)\n",
    "sample_from_model(m_d4, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Why not just set $n=10000$?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pr([the olympics] | m_d4)=0\n"
     ]
    }
   ],
   "source": [
    "# 4-gram model:\n",
    "print('Pr([the olympics] | m_d4)=%g' % pr_q_given_m(['the olympics'], m_d4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pr([the olympics] | m_d2)=0.111111\n"
     ]
    }
   ],
   "source": [
    "# 2-gram model\n",
    "print('Pr([the olympics] | m_d2)=%g' % pr_q_given_m(['the olympics'], m_d2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pr([the, olympics, zebra] | m_d)=0\n"
     ]
    }
   ],
   "source": [
    "# Even for unigram model\n",
    "print('Pr([the, olympics, zebra] | m_d)=%g' % pr_q_given_m(['the', 'olympics', 'zebra'], m_d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If a query does not appear in document $d$, then $P(q|M_d)=0$.\n",
    "\n",
    "\n",
    "- Want to allow some chance that a word not in $d$ will appear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Smoothed Language Model\n",
    "\n",
    "(Laplace smoothing)\n",
    "\n",
    "$\\begin{align} P_{smooth}(q|M_d) = \\prod_{t \\in q} P(t|M_d) = \\prod_{t \\in q} \\frac{tf_{t, d} + \\epsilon}{L_d + V\\epsilon} \\end{align}$\n",
    "\n",
    "- $q:$ query consisting of terms $t$\n",
    "- $M_d:$ language model for document $d$\n",
    "- $tf_{t, d}:$ frequency of term $t$ in document $d$\n",
    "- $L_d:$ number of tokens in $d$\n",
    "- $\\epsilon:$ amount to smooth\n",
    "- $V$: vocabulary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsmoothed model:\n",
      "Counter({'the': 0.2,\n",
      "         'in': 0.1,\n",
      "         'olympics': 0.1,\n",
      "         'medals': 0.1,\n",
      "         'nine': 0.1,\n",
      "         'united': 0.1,\n",
      "         'won': 0.1,\n",
      "         'gold': 0.1,\n",
      "         'states': 0.1})\n",
      "\n",
      "smoothed model1:\n",
      "Counter({'the': 0.15,\n",
      "         'in': 0.1,\n",
      "         'olympics': 0.1,\n",
      "         'medals': 0.1,\n",
      "         'nine': 0.1,\n",
      "         'united': 0.1,\n",
      "         'won': 0.1,\n",
      "         'gold': 0.1,\n",
      "         'states': 0.1,\n",
      "         'zebra': 0.05})\n",
      "\n",
      "smoothed model10:\n",
      "Counter({'the': 0.10909090909090909,\n",
      "         'in': 0.1,\n",
      "         'olympics': 0.1,\n",
      "         'medals': 0.1,\n",
      "         'nine': 0.1,\n",
      "         'united': 0.1,\n",
      "         'won': 0.1,\n",
      "         'gold': 0.1,\n",
      "         'states': 0.1,\n",
      "         'zebra': 0.09090909090909091})\n"
     ]
    }
   ],
   "source": [
    "def doc2model_smooth(doc, smooth_term, vocab):\n",
    "    \"\"\" Convert a document d into a language model M_d. \"\"\"\n",
    "    counts = Counter(doc)\n",
    "    for term in vocab:\n",
    "        counts[term] = (counts[term] + smooth_term) / (1. * len(doc) + smooth_term * len(vocab))\n",
    "    return counts\n",
    "\n",
    "vocab = ['the', 'united', 'states', 'won', 'nine', 'gold', 'medals', 'in', 'olympics', 'zebra']\n",
    "m_d_smooth1 = doc2model_smooth(['the', 'united', 'states', 'won', 'nine', 'gold', 'medals', 'in', 'the', 'olympics'],\n",
    "                               smooth_term=1, vocab=vocab)\n",
    "m_d_smooth10 = doc2model_smooth(['the', 'united', 'states', 'won', 'nine', 'gold', 'medals', 'in', 'the', 'olympics'],\n",
    "                                smooth_term=10, vocab=vocab)\n",
    "print('unsmoothed model:')\n",
    "pprint(m_d)\n",
    "print('\\nsmoothed model1:')\n",
    "pprint(m_d_smooth1)\n",
    "print('\\nsmoothed model10:')\n",
    "pprint(m_d_smooth10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pr([the, olympics, zebra] | m_d_smooth1) =0.00075\n",
      "Pr([the, olympics, zebra] | m_d_smooth10)=0.000991736\n"
     ]
    }
   ],
   "source": [
    "print('Pr([the, olympics, zebra] | m_d_smooth1) =%g' % pr_q_given_m(['the', 'olympics', 'zebra'], m_d_smooth1))\n",
    "print('Pr([the, olympics, zebra] | m_d_smooth10)=%g' % pr_q_given_m(['the', 'olympics', 'zebra'], m_d_smooth10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Problem with Laplace smoothing:**\n",
    "\n",
    "- Assumes that all unseen words are equally likely.\n",
    "  - Effectively adds $\\epsilon$ occurrences to every document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pr([the, olympics, zebra] | m_d_smooth10)=0.000763889\n",
      "Pr([the, olympics, a] | m_d_smooth10)=0.000763889\n"
     ]
    }
   ],
   "source": [
    "# Add 'a' to vocab\n",
    "vocab = ['the', 'united', 'states', 'won', 'nine', 'gold', 'medals', 'in', 'olympics', 'zebra', 'a']\n",
    "m_d_smooth10 = doc2model_smooth(['the', 'united', 'states', 'won', 'nine', 'gold', 'medals', 'in', 'the', 'olympics'],\n",
    "                                smooth_term=10, vocab=vocab)\n",
    "\n",
    "print('Pr([the, olympics, zebra] | m_d_smooth10)=%g'% pr_q_given_m(['the', 'olympics', 'zebra'], m_d_smooth10))\n",
    "print('Pr([the, olympics, a] | m_d_smooth10)=%g' % pr_q_given_m(['the', 'olympics', 'a'], m_d_smooth10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- $d_1:$ the, cat\n",
    "- $d_2:$ dog, cat\n",
    "\n",
    "\n",
    "- $q:$ dog, the\n",
    "\n",
    "Should return $d_2$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "But, Laplace smoothing means missing the word \"dog\" is just as bad as missing the word \"the\".\n",
    "\n",
    "\n",
    "$\\begin{align} P_{smooth}(q|M_d) = \\prod_{t \\in q} P(t|M_d) = \\prod_{t \\in q} \\frac{tf_{t, d} + \\epsilon}{L_d + V\\epsilon} \\end{align}$\n",
    "\n",
    "$\\begin{align} P_{smooth}(q|M_{d_1}) = P(dog|M_{d_1}) * P(the|M_{d_1}) = \\frac{\\epsilon}{2 + V\\epsilon} * \\frac{1 + \\epsilon}{2 + V\\epsilon} \\end{align}$\n",
    "\n",
    "$\\begin{align} P_{smooth}(q|M_{d_2}) = P(dog|M_{d_2}) * P(the|M_{d_2}) = \\frac{1 + \\epsilon}{2 + V\\epsilon} * \\frac{\\epsilon}{2 + V\\epsilon} \\end{align}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Smoothing with collection frequency\n",
    "\n",
    "Let $cf_t$ be the collection frequency of term $t$\n",
    "\n",
    "- That is, the total number of times it occurs (as opposed to $df_t$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Then if term $t$ does not appear in document $d$. \n",
    "\n",
    "- We want $P(t|M_d) < \\frac{cf_t}{T}$\n",
    "- $T=$ total number of tokens in all documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let $M_c$ be the language model for the entire document collection:\n",
    "\n",
    "\n",
    "$\\begin{align} P(t|M_c) = \\frac{cf_{t}}{T} \\end{align}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Dirichlet Smoothing\n",
    "\n",
    "\n",
    "$\\begin{align} P_{dir}(t|M_d) = \\frac{tf_{t, d} + \\alpha P(t|M_c)}{L_d + \\alpha} \\end{align}$\n",
    "\n",
    "- $\\alpha:$ tunable parameter\n",
    "- Larger $\\alpha \\rightarrow$ more smoothing.\n",
    "\n",
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Interpolation Smoothing\n",
    "\n",
    "Alternatively, we can *interpolate* between the document probability and the collection probability:\n",
    "\n",
    "$\\begin{align}P_{interp}(t|M_d) & = & \\lambda P(t|M_d) + (1-\\lambda) P(t|M_c)\\\\\n",
    "& = & \\lambda \\frac{tf_{t, d}}{L_d} + (1-\\lambda) \\frac{cf_{t}}{T} \n",
    "\\end{align}$\n",
    "\n",
    "- $\\lambda$ is a tunable parameter.\n",
    "- Smaller $\\lambda \\rightarrow$ more smoothing.\n",
    "- This is also called *Jelinek-Mercer* smoothing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Thus, the new query likelihood is:\n",
    "\n",
    "\n",
    "$\\begin{align} P_{interp}(q|M_d) = \\prod_{t \\in q} P_{interp}(t|M_d) = \\prod_{t \\in q} \\lambda \\frac{tf_{t, d}}{L_d} + (1-\\lambda) \\frac{cf_{t}}{T}  \\end{align}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Interpolation Example\n",
    "\n",
    "(from [MRS](http://nlp.stanford.edu/IR-book/pdf/12lmodel.pdf) p. 246)\n",
    "\n",
    "- $d_1:$ Xyzzy reports a proﬁt but revenue is down\n",
    "- $d_2:$ Quorus narrows quarter loss but revenue decreases further\n",
    "- $\\lambda=.5$\n",
    "\n",
    "Suppose the query is **revenue down**. Then:\n",
    "\n",
    "$P_{interp}(q|d_1) = $\n",
    "\n",
    "$P_{interp}(q|d_2) = $\n",
    "\n",
    "$\\begin{align}P_{interp}(t|M_d) & = & \\lambda P(t|M_d) + (1-\\lambda) P(t|M_c)\\\\\n",
    "& = & \\lambda \\frac{tf_{t, d}}{L_d} + (1-\\lambda) \\frac{cf_{t}}{T} \n",
    "\\end{align}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Interpolation Example\n",
    "\n",
    "(from [MRS](http://nlp.stanford.edu/IR-book/pdf/12lmodel.pdf) p. 246)\n",
    "\n",
    "- $d_1:$ Xyzzy reports a proﬁt but revenue is down\n",
    "- $d_2:$ Quorus narrows quarter loss but revenue decreases further\n",
    "- $\\lambda=.5$\n",
    "\n",
    "Suppose the query is **revenue down**. Then:\n",
    "\n",
    "$P_{interp}(q|d_1) = [(1/8 + 2/16)/2] * [(1/8 + 1/16)/2] = 1/8 * 3/32 = 3/256$\n",
    "\n",
    "$P_{interp}(q|d_2) = [(1/8 + 2/16)/2] * [(0/8 + 1/16)/2] = 1/8 * 1/32 = 1/256$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Where are the following quantities used, if at all?\n",
    "\n",
    "\n",
    "- Term frequency in a document\n",
    "- Collection frequency of a term\n",
    "- Document frequency of a term\n",
    "- Length normalization of a term\n",
    "\n",
    "\n",
    "$\\begin{align} P_{interp}(q|M_d) = \\prod_{t \\in q} P_{interp}(t|M_d) = \\prod_{t \\in q} \\lambda \\frac{tf_{t, d}}{L_d} + (1-\\lambda) \\frac{cf_{t}}{T}  \\end{align}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Should amount of smoothing ($\\lambda)$ depend on query length?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![qlength](files/qlength.png)\n",
    "\n",
    "Source: [Zhai & Lafferty, 2004](http://galton.uchicago.edu/~lafferty/pdf/smooth-tois.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Language Model vs. tf-idf\n",
    "\n",
    "![lmvstfidf](files/lmvstfidf.png)\n",
    "\n",
    "Source: [MRS](http://nlp.stanford.edu/IR-book/pdf/12lmodel.pdf)\n",
    "\n",
    "\n",
    "\n",
    "$\\begin{align} P_{interp}(q|M_d) = \\prod_{t \\in q} P_{interp}(t|M_d) = \\prod_{t \\in q} \\lambda \\frac{tf_{t, d}}{L_d} + (1-\\lambda) \\frac{cf_{t}}{T}  \\end{align}$\n",
    "\n",
    "vs.\n",
    "\n",
    "$ S_{tfidf}(q, d) = \\sum_{t \\in q} \\begin{align} (1 + \\log(tf_{t, d})) * \\log(\\frac{N}{df_t}) \\end{align}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<table>\n",
    "<tr><td>docID</td> <td>Document text</td></tr>\n",
    "<tr> <td>1</td> <td>click go the shears boys click click click</td> </tr>\n",
    "<tr> <td>2</td> <td>click click</td></tr>\n",
    "<tr> <td>3</td> <td>metal here</td></tr>\n",
    "<tr> <td>4</td> <td>metal shears click here</td></tr>\n",
    "</table>\n",
    "\n",
    "<table>\n",
    "<tr><td>Query</td> <td>Doc 1</td> <td>Doc 2</td> <td>Doc 3</td> <td>Doc 4</td></tr>\n",
    "<tr><td>click</td><td> </td><td> </td><td> </td><td> </td></tr>\n",
    "<tr><td>shears</td><td> </td><td> </td><td> </td><td> </td></tr>\n",
    "<tr><td>click shears</td><td> </td><td> </td><td> </td><td> </td></tr>\n",
    "</table>\n",
    "\n",
    "Let $\\lambda=0.5$.\n",
    "\n",
    "$\\begin{align} P_{interp}(q|M_d) = \\prod_{t \\in q} P_{interp}(t|M_d) = \\prod_{t \\in q} \\lambda \\frac{tf_{t, d}}{L_d} + (1-\\lambda) \\frac{cf_{t}}{T}  \\end{align}$\n",
    "\n",
    "(Source: [MRS](http://nlp.stanford.edu/IR-book/pdf/12lmodel.pdf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
